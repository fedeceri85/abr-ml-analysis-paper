{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare models trained on the primary cohort (Sheffield), the replication cohort (KCL) and both combined.\n",
    "Models are trained and tested either on the same dataset or on the other dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "import pandas as pd\n",
    "import sys\n",
    "import seaborn as sns\n",
    "sns.set_style('ticks')\n",
    "sns.set_context('poster')\n",
    "sys.path.append('../src')\n",
    "import abrTools as at\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,Normalizer\n",
    "from sklearn.metrics import ConfusionMatrixDisplay,confusion_matrix,classification_report\n",
    "from collections import Counter\n",
    "import pretty_confusion_matrix as pcm\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "\n",
    "fs = 195000.0/2.0 # Acquisition sampling rate\n",
    "\n",
    "from datetime import date\n",
    "savefolder = os.path.join('..','results',str(date.today()))\n",
    "\n",
    "#Create saveFolder. Declare the folder explicitly if continuing a previous run.\n",
    "if not os.path.exists(savefolder):\n",
    "    os.makedirs(savefolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the sound level interval between 15 and 85 dB to include the largest possible amount of Replication cohort data, while avoiding imputation. We consider only Click stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowestInt = 15 # Lowest sound level considered\n",
    "highestInt = 85# highest sound level considered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abrTools import loadKingsData, loadSheffieldData,interFunc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sktime.classification.kernel_based import RocketClassifier\n",
    "from sktime.classification.hybrid import HIVECOTEV2\n",
    "from sklearn.feature_selection import f_classif,mutual_info_classif, SelectFpr, SelectPercentile\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrain sheffield models (on a dataset comparable to KCL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for the experiment\n",
    "frequencies = [[100]]\n",
    "suffices =  ['Click']\n",
    "results = []\n",
    "njobs = -1\n",
    "anovaPercentile= 10\n",
    "\n",
    "# Loop through each frequency\n",
    "for i, freq in enumerate(frequencies):\n",
    "    print(freq)\n",
    "    \n",
    "    # Load Sheffield data\n",
    "    X_train, X_test, y_train, y_test, X_full, y_full, dataVersion = loadSheffieldData()\n",
    "\n",
    "    # Random Forest Classifier with ANOVA feature selection\n",
    "    print('Forest - anova')\n",
    "    anova_fs = SelectPercentile(f_classif, percentile=anovaPercentile)\n",
    "    forest_cl = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced', n_jobs=-1, max_depth=None, max_features='sqrt', min_samples_leaf=1, min_samples_split=5, bootstrap=True)\n",
    "    forest_pip = make_pipeline(anova_fs, forest_cl)\n",
    "    \n",
    "    # Check if results already exist, if not, fit the model and save results\n",
    "    if not os.path.exists(os.path.join(savefolder, f'forestSheffield_kFoldCrossValidation_AnovaFS{anovaPercentile}percent' + suffices[i] + '.csv')):\n",
    "        res = at.fitClassificationModel(forest_pip, X_train, y_train, X_test=X_test, y_test=y_test, saveToWandb=False, modelName='Forest classifier', dataVersion=dataVersion, crossValidation=True, makePlot=False, calculatePValue=False, njobs=njobs)\n",
    "        pd.DataFrame(res).to_csv(os.path.join(savefolder, f'forestSheffield_kFoldCrossValidation_AnovaFS{anovaPercentile}percent' + suffices[i] + '.csv'))\n",
    "        results.append(res)\n",
    "        forest_pip.fit(X_train, y_train)\n",
    "        dump(forest_pip, os.path.join(savefolder, f'forestSheffield_kFoldCrossValidation_AnovaFS{anovaPercentile}percent' + suffices[i] + '.joblib'))\n",
    "        pd.DataFrame({'y_test': y_test, 'y_predict': forest_pip.predict(X_test)}).to_csv(os.path.join(savefolder, f'forestSheffield_kFoldCrossValidation_AnovaFS{anovaPercentile}percent' + suffices[i] + 'testResults.csv'))\n",
    "\n",
    "    # Support Vector Classifier with ANOVA feature selection\n",
    "    print('svc - anova')\n",
    "    anova_fs = SelectPercentile(f_classif, percentile=10)\n",
    "    svc_cl = SVC(probability=True, C=0.01, class_weight='balanced', degree=2, gamma=0.01, kernel='poly', shrinking=True)\n",
    "    svc_pip = make_pipeline(anova_fs, svc_cl)\n",
    "    \n",
    "    # Check if results already exist, if not, fit the model and save results\n",
    "    if not os.path.exists(os.path.join(savefolder, f'SVCSheffield_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.csv')):\n",
    "        res = at.fitClassificationModel(svc_pip, X_train, y_train, X_test=X_test, y_test=y_test, saveToWandb=False, modelName='SVC classifier', dataVersion=dataVersion, crossValidation=True, makePlot=False, calculatePValue=False, njobs=njobs)\n",
    "        pd.DataFrame(res).to_csv(os.path.join(savefolder, f'SVCSheffield_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.csv'))\n",
    "        results.append(res)\n",
    "        svc_pip.fit(X_train, y_train)\n",
    "        dump(svc_pip, os.path.join(os.path.join(savefolder, f'SVCSheffield_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.joblib')))\n",
    "        pd.DataFrame({'y_test': y_test, 'y_predict': svc_pip.predict(X_test)}).to_csv(os.path.join(savefolder, f'SVCSheffield_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + 'testResults.csv'))\n",
    "\n",
    "    # XGBoost Classifier with ANOVA feature selection\n",
    "    print('xgboost - anova')\n",
    "    anova_fs = SelectPercentile(f_classif, percentile=10)\n",
    "    sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "    reg = xgb.XGBClassifier(n_estimators=200, verbosity=0, n_jobs=-1, random_state=42, max_depth=3, sample_weight=sample_weights, colsample_bytree=0.8, learning_rate=0.1, subsample=0.6)\n",
    "    xg_pip = make_pipeline(anova_fs, reg)\n",
    "    \n",
    "    # Encode labels for XGBoost\n",
    "    y_train2 = y_train.copy()\n",
    "    y_train2[y_train == '6N'] = 0\n",
    "    y_train2[y_train == 'Repaired'] = 1\n",
    "    y_test2 = y_test.copy()\n",
    "    y_test2[y_test == '6N'] = 0\n",
    "    y_test2[y_test == 'Repaired'] = 1\n",
    "    y_train2 = y_train2.astype(int)\n",
    "    y_test2 = y_test2.astype(int)\n",
    "    \n",
    "    # Check if results already exist, if not, fit the model and save results\n",
    "    if not os.path.exists(os.path.join(savefolder, f'XGBOOSTSheffield_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.csv')):\n",
    "        res = at.fitClassificationModel(xg_pip, X_train, y_train2, X_test=X_test, y_test=y_test2, saveToWandb=False, modelName='XGBOOST', dataVersion=dataVersion, crossValidation=True, makePlot=False, njobs=njobs, encode_labels=True)\n",
    "        pd.DataFrame(res).to_csv(os.path.join(savefolder, f'XGBOOSTSheffield_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.csv'))\n",
    "        results.append(res)\n",
    "        xg_pip.fit(X_train, y_train2)\n",
    "        dump(xg_pip, os.path.join(savefolder, f'XGBOOSTSheffield_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.joblib'))\n",
    "\n",
    "        y_predict2 = xg_pip.predict(X_test)\n",
    "        y_predict = y_predict2.copy().astype(str)\n",
    "        y_predict[y_predict2 == 0] = '6N'\n",
    "        y_predict[y_predict2 == 1] = 'Repaired'\n",
    "        pd.DataFrame({'y_test': y_test, 'y_predict': y_predict}).to_csv(os.path.join(savefolder, f'XGBOOSTSheffield_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + 'testResults.csv'))\n",
    "\n",
    "    # Rocket Classifier with ANOVA feature selection\n",
    "    print('rocket - anova')\n",
    "    anova_fs = SelectPercentile(f_classif, percentile=10)\n",
    "    rocket = RocketClassifier(num_kernels=5000, n_jobs=-1, max_dilations_per_kernel=16, n_features_per_kernel=2, use_multivariate='yes', random_state=42)\n",
    "    rocket_pip = make_pipeline(anova_fs, rocket)\n",
    "    \n",
    "    # Check if results already exist, if not, fit the model and save results\n",
    "    if not os.path.exists(os.path.join(savefolder, f'RocketSheffield_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.csv')):\n",
    "        try:\n",
    "            res = at.fitClassificationModel(rocket_pip, X_train, y_train, X_test=X_test, y_test=y_test, saveToWandb=False, modelName='Rocket classifier', dataVersion=dataVersion, crossValidation=True, makePlot=False, calculatePValue=False, njobs=njobs)\n",
    "        except ValueError:\n",
    "            res = {'accuracy': array([0, 0, 0]), 'roc_auc_score': array([0, 0, 0])}\n",
    "        pd.DataFrame(res).to_csv(os.path.join(savefolder, f'RocketSheffield_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.csv'))\n",
    "        results.append(res)\n",
    "        rocket_pip.fit(X_train, y_train)\n",
    "        dump(rocket_pip, os.path.join(savefolder, f'RocketSheffield_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.joblib'))\n",
    "        pd.DataFrame({'y_test': y_test, 'y_predict': rocket_pip.predict(X_test)}).to_csv(os.path.join(savefolder, f'RocketSheffield_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + 'testResults.csv'))\n",
    "\n",
    "    # MLP Classifier with ANOVA feature selection\n",
    "    print('MLP - anova')\n",
    "    anova_fs = SelectPercentile(f_classif, percentile=10)\n",
    "    mlp = MLPClassifier(solver='lbfgs', random_state=42, early_stopping=True, activation='tanh', alpha=0.05, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=100)\n",
    "    mlp_pip = make_pipeline(anova_fs, mlp)\n",
    "    \n",
    "    # Check if results already exist, if not, fit the model and save results\n",
    "    if not os.path.exists(os.path.join(savefolder, f'MLPSheffield_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.csv')):\n",
    "        res = at.fitClassificationModel(mlp_pip, X_train, y_train, X_test=X_test, y_test=y_test, saveToWandb=False, modelName='Forest classifier', dataVersion=dataVersion, crossValidation=True, makePlot=False, calculatePValue=False, njobs=njobs)\n",
    "        pd.DataFrame(res).to_csv(os.path.join(savefolder, f'MLPSheffield_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.csv'))\n",
    "        results.append(res)\n",
    "        mlp_pip.fit(X_train, y_train)\n",
    "        dump(mlp_pip, os.path.join(savefolder, f'MLPSheffield_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.joblib'))\n",
    "        pd.DataFrame({'y_test': y_test, 'y_predict': mlp_pip.predict(X_test)}).to_csv(os.path.join(savefolder, f'MLPSheffield_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + 'testResults.csv'))\n",
    "\n",
    "    # HIVE-COTE Classifier with ANOVA feature selection\n",
    "    print('hive cote - anova')\n",
    "    anova_fs = SelectPercentile(f_classif, percentile=10)\n",
    "    hc2 = HIVECOTEV2(n_jobs=-1, time_limit_in_minutes=0.2)\n",
    "    hc2_pip = make_pipeline(anova_fs, hc2)\n",
    "    \n",
    "    # Check if results already exist, if not, fit the model and save results\n",
    "    if not os.path.exists(os.path.join(savefolder, f'hivecoteSheffield_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.csv')):\n",
    "        try:\n",
    "            res = at.fitClassificationModel(hc2_pip, X_train, y_train, X_test=X_test, y_test=y_test, saveToWandb=False, modelName='Forest classifier', dataVersion=dataVersion, crossValidation=True, makePlot=False, calculatePValue=False, njobs=njobs)\n",
    "        except ValueError:\n",
    "            res = {'accuracy': array([0, 0, 0]), 'roc_auc_score': array([0, 0, 0])}\n",
    "        pd.DataFrame(res).to_csv(os.path.join(savefolder, f'hivecoteSheffield_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.csv'))\n",
    "        results.append(res)\n",
    "        hc2_pip.fit(X_train, y_train)\n",
    "        dump(hc2_pip, os.path.join(savefolder, f'hivecoteSheffield_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.joblib'))\n",
    "        pd.DataFrame({'y_test': y_test, 'y_predict': hc2_pip.predict(X_test)}).to_csv(os.path.join(savefolder, f'hivecoteSheffield_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + 'testResults.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on KCL data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that KCL data are shifted by 54 points (to the left) to account for the longer distance between mouse and speaker used in the setup (10 cm vs 20 cm) and align Wave 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test,X_kings,y_kings = loadKingsData(shift=54,scaling=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = [[100]]\n",
    "suffices =  ['Click']\n",
    "results = []\n",
    "njobs = -1\n",
    "anovaPercentile= 10\n",
    "dataVersion = 'None'\n",
    "# Loop through each frequency\n",
    "for i, freq in enumerate(frequencies):\n",
    "    print(freq)\n",
    "    # Load data\n",
    "    X_train, X_test, y_train, y_test, X_kings, y_kings = loadKingsData(shift=54, scaling=False)\n",
    "\n",
    "    ### ANOVA FEATURE EXTRACTION\n",
    "    print('Forest - anova')\n",
    "    anova_fs = SelectPercentile(f_classif, percentile=anovaPercentile)\n",
    "    forest_cl = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced', n_jobs=-1, max_depth=None, max_features='sqrt', min_samples_leaf=1, min_samples_split=5, bootstrap=True)\n",
    "    forest_pip = make_pipeline(anova_fs, forest_cl)\n",
    "    \n",
    "    # Check if results already exist, if not, fit and save the model\n",
    "    if not os.path.exists(os.path.join(savefolder, f'forestKings_kFoldCrossValidation_AnovaFS{anovaPercentile}percent' + suffices[i] + '.csv')):\n",
    "        res = at.fitClassificationModel(forest_pip, X_train, y_train, X_test=X_test, y_test=y_test, saveToWandb=False, modelName='Forest classifier', dataVersion=dataVersion,\n",
    "                                        crossValidation=True, makePlot=False, calculatePValue=False, njobs=njobs)\n",
    "        pd.DataFrame(res).to_csv(os.path.join(savefolder, f'forestKings_kFoldCrossValidation_AnovaFS{anovaPercentile}percent' + suffices[i] + '.csv'))\n",
    "        results.append(res)\n",
    "        forest_pip.fit(X_train, y_train)\n",
    "        dump(forest_pip, os.path.join(savefolder, f'forestKings_kFoldCrossValidation_AnovaFS{anovaPercentile}percent' + suffices[i] + '.joblib'))\n",
    "        pd.DataFrame({'y_test': y_test, 'y_predict': forest_pip.predict(X_test)}).to_csv(os.path.join(savefolder, f'forestKings_kFoldCrossValidation_AnovaFS{anovaPercentile}percent' + suffices[i] + 'testResults.csv'))\n",
    "\n",
    "    print('svc - anova')\n",
    "    anova_fs = SelectPercentile(f_classif, percentile=10)\n",
    "    svc_cl = SVC(probability=True, C=0.01, class_weight='balanced', degree=2, gamma=0.01, kernel='poly', shrinking=True)\n",
    "    svc_pip = make_pipeline(anova_fs, svc_cl)\n",
    "    \n",
    "    # Check if results already exist, if not, fit and save the model\n",
    "    if not os.path.exists(os.path.join(savefolder, f'SVCKings_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.csv')):\n",
    "        res = at.fitClassificationModel(svc_pip, X_train, y_train, X_test=X_test, y_test=y_test, saveToWandb=False, modelName='SVC classifier', dataVersion=dataVersion,\n",
    "                                        crossValidation=True, makePlot=False, calculatePValue=False, njobs=njobs)\n",
    "        pd.DataFrame(res).to_csv(os.path.join(savefolder, f'SVCKings_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.csv'))\n",
    "        results.append(res)\n",
    "        svc_pip.fit(X_train, y_train)\n",
    "        dump(svc_pip, os.path.join(os.path.join(savefolder, f'SVCKings_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.joblib')))\n",
    "        pd.DataFrame({'y_test': y_test, 'y_predict': svc_pip.predict(X_test)}).to_csv(os.path.join(savefolder, f'SVCKings_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + 'testResults.csv'))\n",
    "\n",
    "    print('xgboost - anova')\n",
    "    anova_fs = SelectPercentile(f_classif, percentile=10)\n",
    "    sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "    reg = xgb.XGBClassifier(n_estimators=200, verbosity=0, n_jobs=-1, random_state=42, max_depth=3, sample_weight=sample_weights, colsample_bytree=0.8, learning_rate=0.1, subsample=0.6)\n",
    "    xg_pip = make_pipeline(anova_fs, reg)\n",
    "    \n",
    "    # Encode labels for XGBoost\n",
    "    y_train2 = y_train.copy()\n",
    "    y_train2[y_train == '6N'] = 0\n",
    "    y_train2[y_train == 'Repaired'] = 1\n",
    "    y_test2 = y_test.copy()\n",
    "    y_test2[y_test == '6N'] = 0\n",
    "    y_test2[y_test == 'Repaired'] = 1\n",
    "    y_train2 = y_train2.astype(int)\n",
    "    y_test2 = y_test2.astype(int)\n",
    "    \n",
    "    # Check if results already exist, if not, fit and save the model\n",
    "    if not os.path.exists(os.path.join(savefolder, f'XGBOOSTKings_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.csv')):\n",
    "        res = at.fitClassificationModel(xg_pip, X_train, y_train2, X_test=X_test, y_test=y_test2, saveToWandb=False, modelName='XGBOOST', dataVersion=dataVersion,\n",
    "                                        crossValidation=True, makePlot=False, njobs=njobs, encode_labels=True)\n",
    "        pd.DataFrame(res).to_csv(os.path.join(savefolder, f'XGBOOSTKings_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.csv'))\n",
    "        results.append(res)\n",
    "        xg_pip.fit(X_train, y_train2)\n",
    "        dump(xg_pip, os.path.join(savefolder, f'XGBOOSTKings_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.joblib'))\n",
    "        y_predict2 = xg_pip.predict(X_test)\n",
    "        y_predict = y_predict2.copy().astype(str)\n",
    "        y_predict[y_predict2 == 0] = '6N'\n",
    "        y_predict[y_predict2 == 1] = 'Repaired'\n",
    "        pd.DataFrame({'y_test': y_test, 'y_predict': y_predict}).to_csv(os.path.join(savefolder, f'XGBOOSTKings_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + 'testResults.csv'))\n",
    "\n",
    "    print('rocket - anova')\n",
    "    anova_fs = SelectPercentile(f_classif, percentile=10)\n",
    "    rocket = RocketClassifier(num_kernels=5000, n_jobs=-1, max_dilations_per_kernel=16, n_features_per_kernel=2, use_multivariate='yes', random_state=42)\n",
    "    rocket_pip = make_pipeline(anova_fs, rocket)\n",
    "    \n",
    "    # Check if results already exist, if not, fit and save the model\n",
    "    if not os.path.exists(os.path.join(savefolder, f'RocketKings_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.csv')):\n",
    "        try:\n",
    "            res = at.fitClassificationModel(rocket_pip, X_train, y_train, X_test=X_test, y_test=y_test, saveToWandb=False, modelName='Rocket classifier', dataVersion=dataVersion,\n",
    "                                            crossValidation=True, makePlot=False, calculatePValue=False, njobs=njobs)\n",
    "        except ValueError:\n",
    "            res = {'accuracy': array([0, 0, 0]),\n",
    "                   'roc_auc_score': array([0, 0, 0]),\n",
    "                   }\n",
    "        pd.DataFrame(res).to_csv(os.path.join(savefolder, f'RocketKings_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.csv'))\n",
    "        results.append(res)\n",
    "        rocket_pip.fit(X_train, y_train)\n",
    "        dump(rocket_pip, os.path.join(savefolder, f'RocketKings_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.joblib'))\n",
    "        pd.DataFrame({'y_test': y_test, 'y_predict': rocket_pip.predict(X_test)}).to_csv(os.path.join(savefolder, f'RocketKings_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + 'testResults.csv'))\n",
    "\n",
    "    print('MLP - anova')\n",
    "    anova_fs = SelectPercentile(f_classif, percentile=10)\n",
    "    mlp = MLPClassifier(solver='lbfgs', random_state=42, early_stopping=True, activation='tanh', alpha=0.05, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=100)\n",
    "    mlp_pip = make_pipeline(anova_fs, mlp)\n",
    "    \n",
    "    # Check if results already exist, if not, fit and save the model\n",
    "    if not os.path.exists(os.path.join(savefolder, f'MLPKings_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.csv')):\n",
    "        res = at.fitClassificationModel(mlp_pip, X_train, y_train, X_test=X_test, y_test=y_test, saveToWandb=False, modelName='Forest classifier', dataVersion=dataVersion,\n",
    "                                        crossValidation=True, makePlot=False, calculatePValue=False, njobs=njobs)\n",
    "        pd.DataFrame(res).to_csv(os.path.join(savefolder, f'MLPKings_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.csv'))\n",
    "        results.append(res)\n",
    "        mlp_pip.fit(X_train, y_train)\n",
    "        dump(mlp_pip, os.path.join(savefolder, f'MLPKings_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.joblib'))\n",
    "        pd.DataFrame({'y_test': y_test, 'y_predict': mlp_pip.predict(X_test)}).to_csv(os.path.join(savefolder, f'MLPKings_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + 'testResults.csv'))\n",
    "\n",
    "    print('hive cote - anova')\n",
    "    anova_fs = SelectPercentile(f_classif, percentile=10)\n",
    "    hc2 = HIVECOTEV2(n_jobs=-1, time_limit_in_minutes=0.2)\n",
    "    hc2_pip = make_pipeline(anova_fs, hc2)\n",
    "    \n",
    "    # Check if results already exist, if not, fit and save the model\n",
    "    if not os.path.exists(os.path.join(savefolder, f'hivecoteKings_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.csv')):\n",
    "        try:\n",
    "            res = at.fitClassificationModel(hc2_pip, X_train, y_train, X_test=X_test, y_test=y_test, saveToWandb=False, modelName='Forest classifier', dataVersion=dataVersion,\n",
    "                                            crossValidation=True, makePlot=False, calculatePValue=False, njobs=njobs)\n",
    "        except ValueError:\n",
    "            res = {'accuracy': array([0, 0, 0]),\n",
    "                   'roc_auc_score': array([0, 0, 0]),\n",
    "                   }\n",
    "        pd.DataFrame(res).to_csv(os.path.join(savefolder, f'hivecoteKings_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.csv'))\n",
    "        results.append(res)\n",
    "        hc2_pip.fit(X_train, y_train)\n",
    "        dump(hc2_pip, os.path.join(savefolder, f'hivecoteKings_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.joblib'))\n",
    "        pd.DataFrame({'y_test': y_test, 'y_predict': hc2_pip.predict(X_test)}).to_csv(os.path.join(savefolder, f'hivecoteKings_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + 'testResults.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on combined. Same as before, but the two datasets are combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = [[100]]\n",
    "suffices =  ['Click']\n",
    "results = []\n",
    "njobs = -1\n",
    "anovaPercentile= 10\n",
    "\n",
    "for i, freq in enumerate(frequencies):\n",
    "    # Load Kings data\n",
    "    X_kings_train, X_kings_test, y_kings_train, y_kings_test, X_kings, y_kings = loadKingsData(shift=54, scaling=False)\n",
    "\n",
    "    # Load Sheffield data\n",
    "    X_train_Sheffield, X_test_Sheffled, y_train_Sheffield, y_test_Sheffield, X_full, y_full, dataVersion = loadSheffieldData()\n",
    "\n",
    "    # Combine data\n",
    "    X_train = np.vstack((X_train_Sheffield, X_kings_train))\n",
    "    X_test = np.vstack((X_test_Sheffled, X_kings_test))\n",
    "    y_train = np.hstack((y_train_Sheffield, y_kings_train))\n",
    "    y_test = np.hstack((y_test_Sheffield, y_kings_test))\n",
    "\n",
    "    X_combined = np.vstack((X_train, X_test))\n",
    "    y_combined = np.hstack((y_train, y_test))\n",
    "\n",
    "    ### ANOVA FEATURE EXTRACTION\n",
    "    print('Forest - anova')\n",
    "    anova_fs = SelectPercentile(f_classif, percentile=anovaPercentile)\n",
    "    forest_cl = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced', n_jobs=-1, max_depth=None, max_features='sqrt', min_samples_leaf=1, min_samples_split=5, bootstrap=True)\n",
    "    forest_pip = make_pipeline(anova_fs, forest_cl)\n",
    "    \n",
    "    # Check if results already exist, if not, fit and save the model\n",
    "    if not os.path.exists(os.path.join(savefolder, f'forestCombined_kFoldCrossValidation_AnovaFS{anovaPercentile}percent' + suffices[i] + '.csv')):\n",
    "        res = at.fitClassificationModel(forest_pip, X_train, y_train, X_test=X_test, y_test=y_test, saveToWandb=False, modelName='Forest classifier', dataVersion=dataVersion,\n",
    "                                        crossValidation=True, makePlot=False, calculatePValue=False, njobs=njobs)\n",
    "        pd.DataFrame(res).to_csv(os.path.join(savefolder, f'forestCombined_kFoldCrossValidation_AnovaFS{anovaPercentile}percent' + suffices[i] + '.csv'))\n",
    "        results.append(res)\n",
    "        forest_pip.fit(X_train, y_train)\n",
    "        dump(forest_pip, os.path.join(savefolder, f'forestCombined_kFoldCrossValidation_AnovaFS{anovaPercentile}percent' + suffices[i] + '.joblib'))\n",
    "        pd.DataFrame({'y_test': y_test, 'y_predict': forest_pip.predict(X_test)}).to_csv(os.path.join(savefolder, f'forestCombined_kFoldCrossValidation_AnovaFS{anovaPercentile}percent' + suffices[i] + 'testResults.csv'))\n",
    "\n",
    "    print('svc - anova')\n",
    "    anova_fs = SelectPercentile(f_classif, percentile=10)\n",
    "    svc_cl = SVC(probability=True, C=0.01, class_weight='balanced', degree=2, gamma=0.01, kernel='poly', shrinking=True)\n",
    "    svc_pip = make_pipeline(anova_fs, svc_cl)\n",
    "    \n",
    "    # Check if results already exist, if not, fit and save the model\n",
    "    if not os.path.exists(os.path.join(savefolder, f'SVCCombined_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.csv')):\n",
    "        res = at.fitClassificationModel(svc_pip, X_train, y_train, X_test=X_test, y_test=y_test, saveToWandb=False, modelName='SVC classifier', dataVersion=dataVersion,\n",
    "                                        crossValidation=True, makePlot=False, calculatePValue=False, njobs=njobs)\n",
    "        pd.DataFrame(res).to_csv(os.path.join(savefolder, f'SVCCombined_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.csv'))\n",
    "        results.append(res)\n",
    "        svc_pip.fit(X_train, y_train)\n",
    "        dump(svc_pip, os.path.join(savefolder, f'SVCCombined_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.joblib'))\n",
    "        pd.DataFrame({'y_test': y_test, 'y_predict': svc_pip.predict(X_test)}).to_csv(os.path.join(savefolder, f'SVCCombined_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + 'testResults.csv'))\n",
    "\n",
    "    print('xgboost - anova')\n",
    "    anova_fs = SelectPercentile(f_classif, percentile=10)\n",
    "    sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "    reg = xgb.XGBClassifier(n_estimators=200, verbosity=0, n_jobs=-1, random_state=42, max_depth=3, sample_weight=sample_weights, colsample_bytree=0.8, learning_rate=0.1, subsample=0.6)\n",
    "    xg_pip = make_pipeline(anova_fs, reg)\n",
    "    \n",
    "    # Encode labels for XGBoost\n",
    "    y_train2 = y_train.copy()\n",
    "    y_train2[y_train == '6N'] = 0\n",
    "    y_train2[y_train == 'Repaired'] = 1\n",
    "    y_test2 = y_test.copy()\n",
    "    y_test2[y_test == '6N'] = 0\n",
    "    y_test2[y_test == 'Repaired'] = 1\n",
    "    y_train2 = y_train2.astype(int)\n",
    "    y_test2 = y_test2.astype(int)\n",
    "    \n",
    "    # Check if results already exist, if not, fit and save the model\n",
    "    if not os.path.exists(os.path.join(savefolder, f'XGBOOSTCombined_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.csv')):\n",
    "        res = at.fitClassificationModel(xg_pip, X_train, y_train2, X_test=X_test, y_test=y_test2, saveToWandb=False, modelName='XGBOOST', dataVersion=dataVersion,\n",
    "                                        crossValidation=True, makePlot=False, njobs=njobs, encode_labels=True)\n",
    "        pd.DataFrame(res).to_csv(os.path.join(savefolder, f'XGBOOSTCombined_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.csv'))\n",
    "        results.append(res)\n",
    "        xg_pip.fit(X_train, y_train2)\n",
    "        y_predict2 = xg_pip.predict(X_test)\n",
    "        y_predict = y_predict2.copy().astype(str)\n",
    "        y_predict[y_predict2 == 0] = '6N'\n",
    "        y_predict[y_predict2 == 1] = 'Repaired'\n",
    "        dump(xg_pip, os.path.join(savefolder, f'XGBOOSTCombined_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.joblib'))\n",
    "        pd.DataFrame({'y_test': y_test, 'y_predict': y_predict}).to_csv(os.path.join(savefolder, f'XGBOOSTCombined_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + 'testResults.csv'))\n",
    "\n",
    "    print('rocket - anova')\n",
    "    anova_fs = SelectPercentile(f_classif, percentile=10)\n",
    "    rocket = RocketClassifier(num_kernels=5000, n_jobs=-1, max_dilations_per_kernel=16, n_features_per_kernel=2, use_multivariate='yes', random_state=42)\n",
    "    rocket_pip = make_pipeline(anova_fs, rocket)\n",
    "    \n",
    "    # Check if results already exist, if not, fit and save the model\n",
    "    if not os.path.exists(os.path.join(savefolder, f'RocketCombined_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.csv')):\n",
    "        try:\n",
    "            res = at.fitClassificationModel(rocket_pip, X_train, y_train, X_test=X_test, y_test=y_test, saveToWandb=False, modelName='Rocket classifier', dataVersion=dataVersion,\n",
    "                                            crossValidation=True, makePlot=False, calculatePValue=False, njobs=njobs)\n",
    "        except ValueError:\n",
    "            res = {'accuracy': array([0, 0, 0]),\n",
    "                   'roc_auc_score': array([0, 0, 0]),\n",
    "                   }\n",
    "        pd.DataFrame(res).to_csv(os.path.join(savefolder, f'RocketCombined_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.csv'))\n",
    "        results.append(res)\n",
    "        rocket_pip.fit(X_train, y_train)\n",
    "        dump(rocket_pip, os.path.join(savefolder, f'RocketCombined_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.joblib'))\n",
    "        pd.DataFrame({'y_test': y_test, 'y_predict': rocket_pip.predict(X_test)}).to_csv(os.path.join(savefolder, f'RocketCombined_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + 'testResults.csv'))\n",
    "\n",
    "    print('MLP - anova')\n",
    "    anova_fs = SelectPercentile(f_classif, percentile=10)\n",
    "    mlp = MLPClassifier(solver='lbfgs', random_state=42, early_stopping=True, activation='tanh', alpha=0.05, hidden_layer_sizes=(150,), learning_rate_init=0.001, max_iter=100)\n",
    "    mlp_pip = make_pipeline(anova_fs, mlp)\n",
    "    \n",
    "    # Check if results already exist, if not, fit and save the model\n",
    "    if not os.path.exists(os.path.join(savefolder, f'MLPCombined_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.csv')):\n",
    "        res = at.fitClassificationModel(mlp_pip, X_train, y_train, X_test=X_test, y_test=y_test, saveToWandb=False, modelName='Forest classifier', dataVersion=dataVersion,\n",
    "                                        crossValidation=True, makePlot=False, calculatePValue=False, njobs=njobs)\n",
    "        pd.DataFrame(res).to_csv(os.path.join(savefolder, f'MLPCombined_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.csv'))\n",
    "        results.append(res)\n",
    "        mlp_pip.fit(X_train, y_train)\n",
    "        dump(mlp_pip, os.path.join(savefolder, f'MLPCombined_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.joblib'))\n",
    "        pd.DataFrame({'y_test': y_test, 'y_predict': mlp_pip.predict(X_test)}).to_csv(os.path.join(savefolder, f'MLPCombined_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + 'testResults.csv'))\n",
    "\n",
    "    print('hive cote - anova')\n",
    "    anova_fs = SelectPercentile(f_classif, percentile=10)\n",
    "    hc2 = HIVECOTEV2(n_jobs=-1, time_limit_in_minutes=0.2)\n",
    "    hc2_pip = make_pipeline(anova_fs, hc2)\n",
    "    \n",
    "    # Check if results already exist, if not, fit and save the model\n",
    "    if not os.path.exists(os.path.join(savefolder, f'hivecoteCombined_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.csv')):\n",
    "        try:\n",
    "            res = at.fitClassificationModel(hc2_pip, X_train, y_train, X_test=X_test, y_test=y_test, saveToWandb=False, modelName='Forest classifier', dataVersion=dataVersion,\n",
    "                                            crossValidation=True, makePlot=False, calculatePValue=False, njobs=njobs)\n",
    "        except ValueError:\n",
    "            res = {'accuracy': array([0, 0, 0]),\n",
    "                   'roc_auc_score': array([0, 0, 0]),\n",
    "                   }\n",
    "        pd.DataFrame(res).to_csv(os.path.join(savefolder, f'hivecoteCombined_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.csv'))\n",
    "        results.append(res)\n",
    "        hc2_pip.fit(X_train, y_train)\n",
    "        dump(hc2_pip, os.path.join(savefolder, f'hivecoteCombined_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.joblib'))\n",
    "        pd.DataFrame({'y_test': y_test, 'y_predict': hc2_pip.predict(X_test)}).to_csv(os.path.join(savefolder, f'hivecoteCombined_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + 'testResults.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test models on different datasets than trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the previously trained models, test them on a different dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kings_train,X_kings_test,y_kings_train,y_kings_test,X_kings,y_kings = loadKingsData(shift=54,scaling=False)\n",
    "\n",
    "X_train_Sheffield,X_test_Sheffled,y_train_Sheffield,y_test_Sheffield,X_full,y_full, dataVersion = loadSheffieldData()\n",
    "\n",
    "\n",
    "#Combine data\n",
    "X_train = np.vstack((X_train_Sheffield,X_kings_train))\n",
    "X_test = np.vstack((X_test_Sheffled,X_kings_test))\n",
    "y_train = np.hstack((y_train_Sheffield, y_kings_train))\n",
    "y_test = np.hstack((y_test_Sheffield, y_kings_test))\n",
    "\n",
    "X_combined = np.vstack((X_train,X_test))\n",
    "y_combined = np.hstack((y_train,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train: Sheffield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder to save results\n",
    "#savefolder = '..\\\\results\\\\2024-03-18-sheffieldvKings'\n",
    "\n",
    "# Set the ANOVA percentile for feature selection\n",
    "anovaPercentile = 10\n",
    "\n",
    "# Initialize the label encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Define the data type to be used ('Sheffield', 'Kings', 'Combined')\n",
    "dataType = 'Sheffield'  # 'Kings', 'Combined\n",
    "\n",
    "# Define the suffix index\n",
    "i = 0\n",
    "\n",
    "# Iterate over different model types\n",
    "for modelType in ['forest', 'SVC', 'XGBOOST', 'MLP', 'rocket', 'hivecote']:\n",
    "    try:\n",
    "        # Try to load the model without an underscore in the filename\n",
    "        model = load(os.path.join(savefolder, f'{modelType}{dataType}_kFoldCrossValidation_AnovaFS{anovaPercentile}percent' + 'Click' + '.joblib'))\n",
    "    except FileNotFoundError:\n",
    "        # If not found, try to load the model with an underscore in the filename\n",
    "        model = load(os.path.join(savefolder, f'{modelType}{dataType}_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + 'Click' + '.joblib'))\n",
    "    \n",
    "    if modelType == 'XGBOOST':\n",
    "        # Predict on Kings data\n",
    "        y_kings2 = le.fit_transform(y_kings)\n",
    "        y_predict_kings = model.predict(X_kings)\n",
    "        y_predict_kings2 = y_predict_kings.copy().astype(str)\n",
    "        y_predict_kings2[y_predict_kings == 0] = '6N'\n",
    "        y_predict_kings2[y_predict_kings == 1] = 'Repaired'\n",
    "        pd.DataFrame({'y_test': y_kings, 'y_predict': y_predict_kings2}).to_csv(os.path.join(savefolder, f'{modelType}{dataType}_kFoldCrossValidation_AnovaFS{anovaPercentile}percent' + suffices[i] + 'testResults_Kings.csv'))\n",
    "        \n",
    "        # Predict on combined test data\n",
    "        y_predict2 = model.predict(X_test)\n",
    "        y_predict = y_predict2.copy().astype(str)\n",
    "        y_predict[y_predict2 == 0] = '6N'\n",
    "        y_predict[y_predict2 == 1] = 'Repaired'\n",
    "        pd.DataFrame({'y_test': y_test, 'y_predict': y_predict}).to_csv(os.path.join(savefolder, f'{modelType}{dataType}_kFoldCrossValidation_AnovaFS{anovaPercentile}percent' + suffices[i] + 'testResults_Combined.csv'))\n",
    "    \n",
    "    else:\n",
    "        # Predict on Kings data\n",
    "        pd.DataFrame({'y_test': y_kings, 'y_predict': model.predict(X_kings)}).to_csv(os.path.join(savefolder, f'{modelType}{dataType}_kFoldCrossValidation_AnovaFS{anovaPercentile}percent' + suffices[i] + 'testResults_Kings.csv'))\n",
    "        \n",
    "        # Predict on combined test data\n",
    "        pd.DataFrame({'y_test': y_test, 'y_predict': model.predict(X_test)}).to_csv(os.path.join(savefolder, f'{modelType}{dataType}_kFoldCrossValidation_AnovaFS{anovaPercentile}percent' + suffices[i] + 'testResults_Combined.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train: KCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataType = 'Kings'  # 'Sheffield', 'Kings', 'Combined'\n",
    "for modelType in ['forest', 'SVC', 'XGBOOST', 'MLP', 'rocket', 'hivecote']:\n",
    "    try:\n",
    "        # Try to load the model without an underscore in the filename\n",
    "        model = load(os.path.join(savefolder, f'{modelType}{dataType}_kFoldCrossValidation_AnovaFS{anovaPercentile}percent' + 'Click' + '.joblib'))\n",
    "    except FileNotFoundError:\n",
    "        # If not found, try to load the model with an underscore in the filename\n",
    "        model = load(os.path.join(savefolder, f'{modelType}{dataType}_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + 'Click' + '.joblib'))\n",
    "    \n",
    "    if modelType == 'XGBOOST':\n",
    "        # Predict on Sheffield data\n",
    "        y_predict2 = model.predict(X_full)\n",
    "        y_predict = y_predict2.copy().astype(str)\n",
    "        y_predict[y_predict2 == 0] = '6N'\n",
    "        y_predict[y_predict2 == 1] = 'Repaired'\n",
    "        pd.DataFrame({'y_test': y_full, 'y_predict': y_predict}).to_csv(os.path.join(savefolder, f'{modelType}{dataType}_kFoldCrossValidation_AnovaFS{anovaPercentile}percent' + suffices[i] + 'testResults_Sheffield.csv'))\n",
    "        \n",
    "        # Predict on combined test data\n",
    "        y_predict2 = model.predict(X_test)\n",
    "        y_predict = y_predict2.copy().astype(str)\n",
    "        y_predict[y_predict2 == 0] = '6N'\n",
    "        y_predict[y_predict2 == 1] = 'Repaired'\n",
    "        pd.DataFrame({'y_test': y_test, 'y_predict': y_predict}).to_csv(os.path.join(savefolder, f'{modelType}{dataType}_kFoldCrossValidation_AnovaFS{anovaPercentile}percent' + suffices[i] + 'testResults_Combined.csv'))\n",
    "    \n",
    "    else:\n",
    "        # Predict on Sheffield data\n",
    "        pd.DataFrame({'y_test': y_full, 'y_predict': model.predict(X_full)}).to_csv(os.path.join(savefolder, f'{modelType}{dataType}_kFoldCrossValidation_AnovaFS{anovaPercentile}percent' + suffices[i] + 'testResults_Sheffield.csv'))\n",
    "        \n",
    "        # Predict on combined test data\n",
    "        pd.DataFrame({'y_test': y_test, 'y_predict': model.predict(X_test)}).to_csv(os.path.join(savefolder, f'{modelType}{dataType}_kFoldCrossValidation_AnovaFS{anovaPercentile}percent' + suffices[i] + 'testResults_Combined.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train: Combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that testing on the two separate datasets should produce the same results as testing on the \"combined\" test set, as it is made by the same mice (in other words, for each element of the confusion matrix, Sheffield+KCL = combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataType = 'Combined'  # 'Sheffield', 'Kings', 'Combined'\n",
    "for modelType in ['forest', 'SVC', 'XGBOOST', 'MLP', 'rocket', 'hivecote']:\n",
    "    try:\n",
    "        # Try to load the model without an underscore in the filename\n",
    "        model = load(os.path.join(savefolder, f'{modelType}{dataType}_kFoldCrossValidation_AnovaFS{anovaPercentile}percent' + 'Click' + '.joblib'))\n",
    "    except FileNotFoundError:\n",
    "        # If not found, try to load the model with an underscore in the filename\n",
    "        model = load(os.path.join(savefolder, f'{modelType}{dataType}_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + 'Click' + '.joblib'))\n",
    "    \n",
    "    if modelType == 'XGBOOST':\n",
    "        # Print the balanced accuracy score for the combined test set\n",
    "        print(balanced_accuracy_score(model.predict(X_test), le.fit_transform(y_test)))\n",
    "        \n",
    "        # Predict on Sheffield test data\n",
    "        y_predict2 = model.predict(X_test_Sheffled)\n",
    "        y_predict = y_predict2.copy().astype(str)\n",
    "        y_predict[y_predict2 == 0] = '6N'\n",
    "        y_predict[y_predict2 == 1] = 'Repaired'\n",
    "        pd.DataFrame({'y_test': y_test_Sheffield, 'y_predict': y_predict}).to_csv(os.path.join(savefolder, f'{modelType}{dataType}_kFoldCrossValidation_AnovaFS{anovaPercentile}percent' + suffices[i] + 'testResults_Sheffield.csv'))\n",
    "        \n",
    "        # Predict on Kings test data\n",
    "        y_predict2 = model.predict(X_kings_test)\n",
    "        y_predict = y_predict2.copy().astype(str)\n",
    "        y_predict[y_predict2 == 0] = '6N'\n",
    "        y_predict[y_predict2 == 1] = 'Repaired'\n",
    "        pd.DataFrame({'y_test': y_kings_test, 'y_predict': y_predict}).to_csv(os.path.join(savefolder, f'{modelType}{dataType}_kFoldCrossValidation_AnovaFS{anovaPercentile}percent' + suffices[i] + 'testResults_Kings.csv'))\n",
    "      \n",
    "    else:\n",
    "        # Predict on Sheffield test data\n",
    "        pd.DataFrame({'y_test': y_test_Sheffield, 'y_predict': model.predict(X_test_Sheffled)}).to_csv(os.path.join(savefolder, f'{modelType}{dataType}_kFoldCrossValidation_AnovaFS{anovaPercentile}percent' + suffices[i] + 'testResults_Sheffield.csv'))\n",
    "        \n",
    "        # Predict on Kings test data\n",
    "        pd.DataFrame({'y_test': y_kings_test, 'y_predict': model.predict(X_kings_test)}).to_csv(os.path.join(savefolder, f'{modelType}{dataType}_kFoldCrossValidation_AnovaFS{anovaPercentile}percent' + suffices[i] + 'testResults_Kings.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Shapley values for the kings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sktime.classification.kernel_based import RocketClassifier\n",
    "from sktime.classification.hybrid import HIVECOTEV2\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif, SelectFpr, SelectPercentile\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from joblib import dump, load\n",
    "import shap\n",
    "#from fastshap import KernelExplainer\n",
    "\n",
    "# Define the folder to save results\n",
    "savefolder = '../results/2024-10-27-sheffieldvKings-unscaled'\n",
    "\n",
    "# Define the frequencies and suffices for the experiments\n",
    "frequencies = [[100]]  # [100,3000,6000,12000,18000,24000,30000]\n",
    "suffices = ['Click']  # 'NoHighFreq'\n",
    "results = []\n",
    "njobs = -1\n",
    "\n",
    "# Kings dataset processing\n",
    "for i, freq in enumerate(frequencies):\n",
    "    print(freq)\n",
    "    # Load Kings data\n",
    "    X_kings_train, X_kings_test, y_kings_train, y_kings_test, X_kings, y_kings = loadKingsData(shift=54, scaling=False)\n",
    "    X_train = X_kings_train\n",
    "    X_test = X_kings_test\n",
    "    \n",
    "    for anovaPercentile in [10]:\n",
    "        # Random forest model\n",
    "        savefile = os.path.join(savefolder, f'forestKings_kFoldCrossValidation_AnovaFS{anovaPercentile}percent' + suffices[i] + 'ShapCoeff.csv')\n",
    "        if not os.path.exists(savefile):\n",
    "            try:\n",
    "                model = load(os.path.join(savefolder, f'forestKings_kFoldCrossValidation_AnovaFS{anovaPercentile}percent' + suffices[i] + '.joblib'))\n",
    "                X_test_reduced = model[0].transform(X_test)\n",
    "                X_train_reduced = model[0].transform(X_train)\n",
    "                X100 = shap.utils.sample(X_train_reduced, 100)\n",
    "                ke = shap.TreeExplainer(model[1], X100, approximate=True)\n",
    "                sv = ke.shap_values(X_test_reduced)\n",
    "                class1Coeff = model[0].inverse_transform(sv[:, :, 0])\n",
    "                class2Coeff = model[0].inverse_transform(sv[:, :, 1])\n",
    "                pd.DataFrame(class1Coeff.T).to_csv(savefile)\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "        \n",
    "        # XGBoost model\n",
    "        savefile = os.path.join(savefolder, f'XGBOOSTKings_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + 'ShapCoeff.csv')\n",
    "        if not os.path.exists(savefile):\n",
    "            try:\n",
    "                model = load(os.path.join(savefolder, f'XGBOOSTKings_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.joblib'))\n",
    "                X_test_reduced = model[0].transform(X_test)\n",
    "                X_train_reduced = model[0].transform(X_train)\n",
    "                X100 = shap.utils.sample(X_train_reduced, 100)\n",
    "                ke = shap.TreeExplainer(model[1], X100, approximate=True)\n",
    "                sv = ke.shap_values(X_test_reduced)\n",
    "                class1Coeff = model[0].inverse_transform(sv)\n",
    "                pd.DataFrame(class1Coeff.T).to_csv(savefile)\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "\n",
    "        # Other models (e.g., SVC)\n",
    "        for modelname in ['SVCKings']:  # :, 'hivecote','Rocket']:,'MLPKings'\n",
    "            print(modelname)\n",
    "            savefile = os.path.join(savefolder, f'{modelname}_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + 'ShapCoeff.csv')\n",
    "            if not os.path.exists(savefile):\n",
    "                try:\n",
    "                    model = load(os.path.join(savefolder, f'{modelname}_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.joblib'))\n",
    "                    X_test_reduced = model[0].transform(X_test[:5, :])  # we test on a subsample of data\n",
    "                    X_train_reduced = model[0].transform(X_train)\n",
    "                    X100 = shap.utils.sample(X_train_reduced, 50)  # we subsample 50 samples to speed up\n",
    "                    ke = shap.KernelExplainer(model[1].predict_proba, X100, approximate=True, check_additivity=False)\n",
    "                    sv = ke.shap_values(X_test_reduced)\n",
    "                    if sv.ndim == 3:\n",
    "                        class1Coeff = model[0].inverse_transform(sv[:, :, 0])\n",
    "                    else:\n",
    "                        if len(sv) > 1:\n",
    "                            class1Coeff = model[0].inverse_transform(sv[0])\n",
    "                        else:\n",
    "                            class1Coeff = model[0].inverse_transform(sv)\n",
    "                    pd.DataFrame(class1Coeff.T).to_csv(savefile)\n",
    "                except FileNotFoundError:\n",
    "                    pass\n",
    "\n",
    "# Sheffield dataset processing\n",
    "for i, freq in enumerate(frequencies):\n",
    "    print(freq)\n",
    "    # Load Sheffield data\n",
    "    X_train_Sheffield, X_test_Sheffled, y_train_Sheffield, y_test_Sheffield, X_full, y_full, dataVersion = loadSheffieldData(shift=54)\n",
    "    X_train = X_train_Sheffield\n",
    "    X_test = X_test_Sheffled\n",
    "    \n",
    "    for anovaPercentile in [10]:\n",
    "        # Random forest model\n",
    "        savefile = os.path.join(savefolder, f'forestSheffield_kFoldCrossValidation_AnovaFS{anovaPercentile}percent' + suffices[i] + 'ShapCoeff.csv')\n",
    "        if not os.path.exists(savefile):\n",
    "            try:\n",
    "                model = load(os.path.join(savefolder, f'forestSheffield_kFoldCrossValidation_AnovaFS{anovaPercentile}percent' + suffices[i] + '.joblib'))\n",
    "                X_test_reduced = model[0].transform(X_test)\n",
    "                X_train_reduced = model[0].transform(X_train)\n",
    "                X100 = shap.utils.sample(X_train_reduced, 100)\n",
    "                ke = shap.TreeExplainer(model[1], X100, approximate=True)\n",
    "                sv = ke.shap_values(X_test_reduced)\n",
    "                class1Coeff = model[0].inverse_transform(sv[:, :, 0])\n",
    "                class2Coeff = model[0].inverse_transform(sv[:, :, 1])\n",
    "                pd.DataFrame(class1Coeff.T).to_csv(savefile)\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "        \n",
    "        # XGBoost model\n",
    "        savefile = os.path.join(savefolder, f'XGBOOSTSheffield_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + 'ShapCoeff.csv')\n",
    "        if not os.path.exists(savefile):\n",
    "            try:\n",
    "                model = load(os.path.join(savefolder, f'XGBOOSTSheffield_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.joblib'))\n",
    "                X_test_reduced = model[0].transform(X_test)\n",
    "                X_train_reduced = model[0].transform(X_train)\n",
    "                X100 = shap.utils.sample(X_train_reduced, 100)\n",
    "                ke = shap.TreeExplainer(model[1], X100, approximate=True)\n",
    "                sv = ke.shap_values(X_test_reduced)\n",
    "                class1Coeff = model[0].inverse_transform(sv)\n",
    "                pd.DataFrame(class1Coeff.T).to_csv(savefile)\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "        \n",
    "        # Other models (e.g., SVC)\n",
    "        for modelname in ['SVCSheffield']:  # :, 'hivecote','Rocket']:,'MLPSheffield'\n",
    "            print(modelname)\n",
    "            savefile = os.path.join(savefolder, f'{modelname}_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + 'ShapCoeff.csv')\n",
    "            if not os.path.exists(savefile):\n",
    "                try:\n",
    "                    model = load(os.path.join(savefolder, f'{modelname}_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.joblib'))\n",
    "                    X_test_reduced = model[0].transform(X_test[:5, :])  # we test on a subsample of data\n",
    "                    X_train_reduced = model[0].transform(X_train)\n",
    "                    X100 = shap.utils.sample(X_train_reduced, 50)  # we subsample 50 samples to speed up\n",
    "                    ke = shap.KernelExplainer(model[1].predict_proba, X100, approximate=True, check_additivity=False)\n",
    "                    sv = ke.shap_values(X_test_reduced)\n",
    "                    if sv.ndim == 3:\n",
    "                        class1Coeff = model[0].inverse_transform(sv[:, :, 0])\n",
    "                    else:\n",
    "                        if len(sv) > 1:\n",
    "                            class1Coeff = model[0].inverse_transform(sv[0])\n",
    "                        else:\n",
    "                            class1Coeff = model[0].inverse_transform(sv)\n",
    "                    pd.DataFrame(class1Coeff.T).to_csv(savefile)\n",
    "                except FileNotFoundError:\n",
    "                    pass\n",
    "\n",
    "# Combined dataset processing\n",
    "for i, freq in enumerate(frequencies):\n",
    "    print(freq)\n",
    "    # Load Kings and Sheffield data\n",
    "    X_kings_train, X_kings_test, y_kings_train, y_kings_test, X_kings, y_kings = loadKingsData(shift=54, scaling=False)\n",
    "    X_train_Sheffield, X_test_Sheffled, y_train_Sheffield, y_test_Sheffield, X_full, y_full, dataVersion = loadSheffieldData(shift=54)\n",
    "    \n",
    "    # Combine Kings and Sheffield data\n",
    "    X_train = np.vstack((X_train_Sheffield, X_kings_train))\n",
    "    X_test = np.vstack((X_test_Sheffled, X_kings_test))\n",
    "    y_train = np.hstack((y_train_Sheffield, y_kings_train))\n",
    "    y_test = np.hstack((y_test_Sheffield, y_kings_test))\n",
    "    X_combined = np.vstack((X_train, X_test))\n",
    "    y_combined = np.hstack((y_train, y_test))\n",
    "\n",
    "    for anovaPercentile in [10]:\n",
    "        # Random forest model\n",
    "        savefile = os.path.join(savefolder, f'forestCombined_kFoldCrossValidation_AnovaFS{anovaPercentile}percent' + suffices[i] + 'ShapCoeff.csv')\n",
    "        if not os.path.exists(savefile):\n",
    "            try:\n",
    "                model = load(os.path.join(savefolder, f'forestCombined_kFoldCrossValidation_AnovaFS{anovaPercentile}percent' + suffices[i] + '.joblib'))\n",
    "                X_test_reduced = model[0].transform(X_test)\n",
    "                X_train_reduced = model[0].transform(X_train)\n",
    "                X100 = shap.utils.sample(X_train_reduced, 100)\n",
    "                ke = shap.TreeExplainer(model[1], X100, approximate=True)\n",
    "                sv = ke.shap_values(X_test_reduced)\n",
    "                class1Coeff = model[0].inverse_transform(sv[:, :, 0])\n",
    "                class2Coeff = model[0].inverse_transform(sv[:, :, 1])\n",
    "                pd.DataFrame(class1Coeff.T).to_csv(savefile)\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "        \n",
    "        # XGBoost model\n",
    "        savefile = os.path.join(savefolder, f'XGBOOSTCombined_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + 'ShapCoeff.csv')\n",
    "        if not os.path.exists(savefile):\n",
    "            try:\n",
    "                model = load(os.path.join(savefolder, f'XGBOOSTCombined_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.joblib'))\n",
    "                X_test_reduced = model[0].transform(X_test)\n",
    "                X_train_reduced = model[0].transform(X_train)\n",
    "                X100 = shap.utils.sample(X_train_reduced, 100)\n",
    "                ke = shap.TreeExplainer(model[1], X100, approximate=True)\n",
    "                sv = ke.shap_values(X_test_reduced)\n",
    "                class1Coeff = model[0].inverse_transform(sv)\n",
    "                pd.DataFrame(class1Coeff.T).to_csv(savefile)\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "\n",
    "        # Other models (e.g., SVC)\n",
    "        for modelname in ['SVCCombined']:  # :, 'hivecote','Rocket']:,'MLPCombined'\n",
    "            print(modelname)\n",
    "            savefile = os.path.join(savefolder, f'{modelname}_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + 'ShapCoeff.csv')\n",
    "            if not os.path.exists(savefile):\n",
    "                try:\n",
    "                    model = load(os.path.join(savefolder, f'{modelname}_kFoldCrossValidation_AnovaFS{anovaPercentile}percent_' + suffices[i] + '.joblib'))\n",
    "                    X_test_reduced = model[0].transform(X_test[:5, :])  # we test on a subsample of data\n",
    "                    X_train_reduced = model[0].transform(X_train)\n",
    "                    X100 = shap.utils.sample(X_train_reduced, 50)  # we subsample 50 samples to speed up\n",
    "                    ke = shap.KernelExplainer(model[1].predict_proba, X100, approximate=True, check_additivity=False)\n",
    "                    sv = ke.shap_values(X_test_reduced)\n",
    "                    if sv.ndim == 3:\n",
    "                        class1Coeff = model[0].inverse_transform(sv[:, :, 0])\n",
    "                    else:\n",
    "                        if len(sv) > 1:\n",
    "                            class1Coeff = model[0].inverse_transform(sv[0])\n",
    "                        else:\n",
    "                            class1Coeff = model[0].inverse_transform(sv)\n",
    "                    pd.DataFrame(class1Coeff.T).to_csv(savefile)\n",
    "                except FileNotFoundError:\n",
    "                    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abr-ml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
