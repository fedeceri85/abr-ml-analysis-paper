{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimisation for RF, XGBOOST, MLP, Rocket, SVC models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform parameters search optimising for recall, f1 score and balanced accuracy. At the moment, f1 score is used for parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "import pandas as pd\n",
    "import sys\n",
    "import seaborn as sns\n",
    "sys.path.append('../src')\n",
    "import abrTools as at\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,Normalizer\n",
    "from sklearn.metrics import ConfusionMatrixDisplay,confusion_matrix,classification_report\n",
    "from collections import Counter\n",
    "import pretty_confusion_matrix as pcm\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "\n",
    "fs = 195000.0/2.0 # Acquisition sampling rate\n",
    "\n",
    "from datetime import date\n",
    "# savefolder = os.path.join('..','results',str(date.today()))\n",
    "\n",
    "# if not os.path.exists(savefolder):\n",
    "#     os.makedirs(savefolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,  X_test,y_train,y_test,dataVersion = at.createClassificationDataset(test_size=0.25,oversample=False,ages=[1,],frequencies=[100,3000,6000,12000,18000,24000,30000,36000,42000])\n",
    "X = np.vstack([X_train,X_test])\n",
    "y = np.hstack([y_train,y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.feature_selection import f_classif,mutual_info_classif, SelectFpr, SelectPercentile\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from joblib import dump, load\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sktime.classification.kernel_based import RocketClassifier\n",
    "from sktime.classification.hybrid import HIVECOTEV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter search for XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import make_scorer,recall_score,balanced_accuracy_score,f1_score\n",
    "anova_fs = SelectPercentile(f_classif,percentile=10)\n",
    "sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "reg = xgb.XGBClassifier(use_label_encoder=False,n_estimators=795,verbosity=0,n_jobs=-1,random_state=42,max_depth=21,sample_weight=sample_weights)\n",
    "xg_pip = make_pipeline(anova_fs,reg)\n",
    "\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "        'xgbclassifier__n_estimators': [50, 100, 200],                     # 3 values\n",
    "        'xgbclassifier__learning_rate': [0.01, 0.05, 0.1],                 # 3 values\n",
    "        'xgbclassifier__max_depth': [3, 5, 7, 10],                         # 4 values\n",
    "        'xgbclassifier__subsample': [0.6, 0.8, 1.0],                      # 3 values\n",
    "        'xgbclassifier__colsample_bytree': [0.6, 0.8, 1.0],                # 3 values\n",
    "    }\n",
    "    \n",
    "\n",
    "\n",
    "y_train2 = y_train.copy()\n",
    "y_train2[y_train=='6N']=0\n",
    "y_train2[y_train=='Repaired']=1\n",
    "y_test2 = y_test.copy()\n",
    "y_test2[y_test=='6N']=0\n",
    "y_test2[y_test=='Repaired']=1\n",
    "\n",
    "y_train2 = y_train2.astype(int)\n",
    "y_test2 = y_test2.astype(int)\n",
    "# Perform GridSearchCV with cross-validation\n",
    "grid_search = GridSearchCV(estimator=xg_pip, \n",
    "                           param_grid=param_grid, \n",
    "                           cv=5,                          # 5-fold cross-validation\n",
    "                           #scoring=make_scorer(recall_score,pos_label=0),              # Optimize for recall \\make_scorer(balanced_accuracy_score)\n",
    "                           scoring = make_scorer(f1_score,pos_label=0),\n",
    "                           #scoring = make_scorer(balanced_accuracy_score),\n",
    "\n",
    "                           verbose=1,                     # Output progress\n",
    "                           n_jobs=-1)                     # Use all processors\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search.fit(X_train, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary of results\n",
    "best_params_recall = {'xgbclassifier__colsample_bytree': 0.8, # Best parameters using recall as a scoring metric\n",
    " 'xgbclassifier__learning_rate': 0.1,\n",
    " 'xgbclassifier__max_depth': 3,\n",
    " 'xgbclassifier__n_estimators': 200,\n",
    " 'xgbclassifier__subsample': 0.6}\n",
    "\n",
    "\n",
    "best_params_f1_score = {'xgbclassifier__colsample_bytree': 0.8,\n",
    " 'xgbclassifier__learning_rate': 0.1,\n",
    " 'xgbclassifier__max_depth': 3,\n",
    " 'xgbclassifier__n_estimators': 200,\n",
    " 'xgbclassifier__subsample': 0.6}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter search for Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_fs = SelectPercentile(f_classif,percentile=10)\n",
    "forest_cl = RandomForestClassifier(n_estimators=1000,random_state=42,class_weight='balanced',n_jobs=-1)\n",
    "forest_pip = make_pipeline(anova_fs,forest_cl)\n",
    "\n",
    "param_grid = {\n",
    "    'randomforestclassifier__n_estimators': [50, 100, 200, 300, 1000],  # Number of trees\n",
    "    'randomforestclassifier__max_depth': [None, 5, 10, 30, 50],          # Maximum depth of the tree\n",
    "    'randomforestclassifier__min_samples_split': [2, 5, 10],             # Minimum number of samples required to split a node\n",
    "    'randomforestclassifier__min_samples_leaf': [1, 2,  6, 8],             # Minimum number of samples required to be at a leaf node\n",
    "    'randomforestclassifier__bootstrap': [True, False],                      # Whether bootstrap samples are used when building trees\n",
    "    'randomforestclassifier__max_features': ['auto', 'sqrt', 'log2'],  # Number of features to consider for the best split\n",
    "    'randomforestclassifier__class_weight': [None, 'balanced'],              # Adjusting weights for handling class imbalance\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV with cross-validation\n",
    "grid_search = GridSearchCV(estimator=forest_pip, \n",
    "                           param_grid=param_grid, \n",
    "                           cv=5,                          # 5-fold cross-validation\n",
    "                           #scoring=make_scorer(recall_score,pos_label='6N'),              # Optimize for recall \\make_scorer(balanced_accuracy_score)\n",
    "                           scoring = make_scorer(f1_score,pos_label='6N'),\n",
    "                           # scoring = make_scorer(balanced_accuracy_score),\n",
    "                           verbose=1,                     # Output progress\n",
    "                           n_jobs=-1)                     # Use all processors\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_recall = {'randomforestclassifier__bootstrap': True, 'randomforestclassifier__class_weight': 'balanced', 'randomforestclassifier__max_depth': None, 'randomforestclassifier__max_features': 'sqrt', 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 2, 'randomforestclassifier__n_estimators': 100}\n",
    "best_score = 0.7928571428571429\n",
    "\n",
    "best_params_f1_score = {'randomforestclassifier__bootstrap': True, 'randomforestclassifier__class_weight': None, 'randomforestclassifier__max_depth': None, 'randomforestclassifier__max_features': 'sqrt', 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 5, 'randomforestclassifier__n_estimators': 100}\n",
    "\n",
    "best_score_f1_score = 0.81\n",
    "\n",
    "\n",
    "best_params_balanced_accuracy = {'randomforestclassifier__bootstrap': True, 'randomforestclassifier__class_weight': None, 'randomforestclassifier__max_depth': None, 'randomforestclassifier__max_features': 'sqrt', 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 5, 'randomforestclassifier__n_estimators': 100}\n",
    "0.8335317460317461"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter search for SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform GridSearchCV with cross-validation\n",
    "anova_fs = SelectPercentile(f_classif,percentile=10)\n",
    "svc_cl = SVC(probability=True,kernel='linear',C=0.2,class_weight='balanced')\n",
    "svc_pip = make_pipeline(anova_fs,svc_cl)\n",
    "\n",
    "param_grid = {\n",
    "    'svc__C': [0.01, 0.1, 1],                # Regularization parameter\n",
    "    'svc__kernel': ['linear', 'rbf', 'poly', 'sigmoid'],  # Kernel type\n",
    "    'svc__gamma': ['scale', 'auto', 0.001, 0.01, 0.1],  # Kernel coefficient (for rbf, poly, sigmoid)\n",
    "    'svc__degree': [2, 3, 4],                         # Degree of the polynomial kernel (used if kernel='poly')\n",
    "    'svc__shrinking': [True, False],                  # Whether to use the shrinking heuristic\n",
    "    'svc__class_weight': [None, 'balanced']           # Adjusting weights for handling class imbalance\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=svc_pip, \n",
    "                           param_grid=param_grid, \n",
    "                           cv=5,                          # 5-fold cross-validation\n",
    "                           #scoring=make_scorer(recall_score,pos_label='6N'),              # Optimize for recall \\make_scorer(balanced_accuracy_score)\n",
    "                           scoring = make_scorer(f1_score,pos_label='6N'),\n",
    "                           #scoring = make_scorer(balanced_accuracy_score),\n",
    "                           verbose=1,                     # Output progress\n",
    "                           n_jobs=-1)                     # Use all processors\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_recall = {'svc__C': 1, 'svc__class_weight': 'balanced', 'svc__degree': 2, 'svc__gamma': 0.01, 'svc__kernel': 'sigmoid', 'svc__shrinking': True}\n",
    "best_score = 0.9464285714285714\n",
    "\n",
    "best_params_f1_score = {'svc__C': 0.01, 'svc__class_weight': None, 'svc__degree': 2, 'svc__gamma': 0.01, 'svc__kernel': 'poly', 'svc__shrinking': True}\n",
    "best_score_f1_score = 0.833\n",
    "\n",
    "best_params_balanced_accuracy ={'svc__C': 0.01, 'svc__class_weight': None, 'svc__degree': 2, 'svc__gamma': 'scale', 'svc__kernel': 'linear', 'svc__shrinking': True}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rocket parameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_fs = SelectPercentile(f_classif,percentile=10)    \n",
    "rocket = RocketClassifier(num_kernels=1000,n_jobs=-1,random_state=42)\n",
    "rocket_pip = make_pipeline(anova_fs,rocket)\n",
    "\n",
    "param_grid= {\n",
    "        'rocketclassifier__num_kernels': [100,1000,5000],   # Number of random convolution kernels\n",
    "        'rocketclassifier__max_dilations_per_kernel': [16,32, 64],        # Max dilations per kernel\n",
    "        'rocketclassifier__n_features_per_kernel': [2, 4, 8],               # Number of features per kernel\n",
    "         'rocketclassifier__use_multivariate': ['yes', 'no'],                # Whether to use multivariate data or not\n",
    "     \n",
    "    }\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rocket_pip, \n",
    "                           param_grid=param_grid, \n",
    "                           cv=5,                          # 5-fold cross-validation\n",
    "                           #scoring=make_scorer(recall_score,pos_label='6N'),              # Optimize for recall \\make_scorer(balanced_accuracy_score)\n",
    "                           scoring = make_scorer(f1_score,pos_label='6N'),\n",
    "                           # scoring = make_scorer(balanced_accuracy_score),\n",
    "                           verbose=3,                     # Output progress\n",
    "                           n_jobs=-1)                     # Use all processors\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_recall = {'rocketclassifier__max_dilations_per_kernel': 16, 'rocketclassifier__n_features_per_kernel': 2, 'rocketclassifier__num_kernels': 5000, 'rocketclassifier__use_multivariate': 'yes'}\n",
    "best_score_recall = 0.8392857142857142\n",
    "\n",
    "best_params_f1_score = {'rocketclassifier__max_dilations_per_kernel': 16, 'rocketclassifier__n_features_per_kernel': 2, 'rocketclassifier__num_kernels': 5000, 'rocketclassifier__use_multivariate': 'yes'}\n",
    "best_score_f1_Score = 0.87\n",
    "\n",
    "best_params_balanced_accuracy = {'rocketclassifier__max_dilations_per_kernel': 16, 'rocketclassifier__n_features_per_kernel': 2, 'rocketclassifier__num_kernels': 5000, 'rocketclassifier__use_multivariate': 'yes'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search for MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_fs = SelectPercentile(f_classif,percentile=10)\n",
    "mlp = MLPClassifier(solver = 'lbfgs',random_state=42, early_stopping=True)\n",
    "mlp_pip = make_pipeline(anova_fs,mlp)\n",
    "\n",
    "param_grid = {\n",
    "        'mlpclassifier__hidden_layer_sizes': [(50,), (100,), (150,), (100, 50)],  # 4 values\n",
    "        'mlpclassifier__activation': ['relu', 'tanh'],                            # 2 values\n",
    "        'mlpclassifier__learning_rate_init': [0.001, 0.01, 0.1],                  # 3 values\n",
    "        'mlpclassifier__alpha': [ 0.001, 0.01,0.05,0.1],                           # 4 values\n",
    "        'mlpclassifier__max_iter': [100,200, 300]                                     # 2 values\n",
    "    }\n",
    "\n",
    "grid_search = GridSearchCV(estimator=mlp_pip, \n",
    "                           param_grid=param_grid, \n",
    "                           cv=5,                          # 5-fold cross-validation\n",
    "                           #scoring=make_scorer(recall_score,pos_label='6N'),              # Optimize for recall \\make_scorer(balanced_accuracy_score)\n",
    "                           scoring = make_scorer(f1_score,pos_label='6N'),                          \n",
    "                           #scoring = make_scorer(balanced_accuracy_score),\n",
    "                           verbose=3,                     # Output progress\n",
    "                           n_jobs=-1)                     # Use all processors\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_recall = {\n",
    "'activation':'relu',\n",
    "'alpha':0.1,\n",
    "'hidden_layer_size':100,\n",
    "'learning_rate_init':0.001,\n",
    "'max_iter':100\n",
    "}\n",
    "best_score_recall = 0.89\n",
    "\n",
    "\n",
    "best_params_f1_score={'mlpclassifier__activation': 'tanh', 'mlpclassifier__alpha': 0.05, 'mlpclassifier__hidden_layer_sizes': (150,), 'mlpclassifier__learning_rate_init': 0.001, 'mlpclassifier__max_iter': 100}\n",
    "best_score_f1_Score = 0.8667948717948718\n",
    "\n",
    "\n",
    "best_params_balanced_accuracy={'mlpclassifier__activation': 'tanh', 'mlpclassifier__alpha': 0.1, 'mlpclassifier__hidden_layer_sizes': (50,), 'mlpclassifier__learning_rate_init': 0.001, 'mlpclassifier__max_iter': 200}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abr-ml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
